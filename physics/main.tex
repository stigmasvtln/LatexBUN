\documentclass[bachelor, och, referat ]{SCWorks}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\newcommand{\eqdef}{\stackrel {\rm def}{=}}
\usepackage{indentfirst}
\newtheorem{lem}{Лемма}

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Энтропия и вероятность, статистический смысл энтропии. Информационный смысл энтропии}

% Курс
\course{1}

% Группа
\group{111}

\napravlenie{02.03.02 "--- Фундаментальная информатика и информационные технологии}

\studenttitle{Студентки}


\author{Кляулиной Светланы Борисовны}

% Заведующий кафедрой
\chtitle{доцент, к.\,ф.-м.\,н.} % степень, звание
\chname{С.\,В.\,Миронов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{} %должность, степень, звание
\saname{В.\,Г.\,Молчанов}

% Год выполнения отчета
\date{2022}

\maketitle

\section*{Введение.}
Энтропия принадлежит к числу важнейших понятий физики. Энтропия как физическая величина была введена в термодинамику Р. Клаузиусом в 1865 г. и оказалась настолько важной и общезначимой, что быстро завоевала сначала другие области физики, а затем проникла и в смежные науки: химию, биологию, теорию информации и т.д. Понятие энтропии с самого начала оказалось трудным для восприятия в отличие, например, от другой физической величины – температуры. Эта трудность сохранилась и для тех, кто впервые знакомится с термодинамикой. Она носит чисто психологический характер и связана с невозможностью непосредственного восприятия энтропии, отсутствием “градусника”, который бы измерял энтропию, как измеряют температуру. Вместе с тем более глубокое понимание температуры, завершившееся формулировкой “нулевого начала”, показывает, что понятие температуры и энтропии одинаковы по сложности. Понятие температуры вводится “нулевым началом”, понятие энтропии – вторым началом.
 Термодинамика в силу феноменологического характера не может вскрыть физический смысл как энтропии, так и температуры. Эту задачу решает статистическая физика. Статистическая интерпретация энтропии позволила математикам обобщить понятие энтропии и ввести метрическую энтропию как абстрактную величину, характеризующую поведение неустойчивых динамических систем с экспоненциальной расходимостью близких в начальный момент времени траекторий (энтропия Крылова–Колмогорова–Синая). Метрическая энтропия – абстрактное математическое понятие, слишком далеко находящееся от практических задач, рассматриваемых в настоящей статье, поэтому здесь оно обсуждаться не будет.

\newpage

\section{Энтропия, и её виды.}
Энтропия вводится вторым началом. В формулировке А. Зоммерфельда оно звучит так: “Каждая термодинамическая система обладает функцией состояния, называемой энтропией. Энтропия вычисляется следующим образом. Система переводится из произвольно выбранного начального состояния в соответствующее конечное состояние через последовательность состояний равновесия, вычисляются все подводимые при этом порции тепла δQ, делятся каждая на соответствующую ей абсолютную температуру, и все полученные таким образом значения суммируются. При реальных (в современной терминологии – необратимых) процессах энтропия замкнутой системы возрастает”. Таким образом,
Существуют три определения физической энтропии.
Термодинамическое.
 Понятие энтропии впервые было введено Клаузиусом как мера необратимогорассеяния энергии. Для обратимых (квазиравновесных) процессов оно было определено так.
 Несмотря на то, что энтропия выражается через процессы, она является функцией состояния, то есть каждому состоянию соответствует определённое её значение. Однако, как видно из формул, она определена с точностью до константы, и выбор состояния с нулевым значением условен. Основываясь на третьем начале термодинамики, за нулевое значение энтропии принимают таковое у системы с
температурой, равной абсолютному нулю. Для необратимых процессов выполняется неравенство (следующее из неравенства Клаузиуса): 


\newpage

\section{Энтропия, вероятность и принцип Больцмана.}
Энтропия – характеризует ту часть полной энергии системы, которая не может быть использована для производства работы, представляет собой отработанную энергию.
Согласно второму началу термодинамики энтропия в замкнутой системе постоянно возрастает и в конечном итоге стремится к своему максимальному значению.
Более глубокое толкование понятия энтропии и было дано с позиций статистической физики – если каждое макроскопическое состояние газа может быть получено с определенной вероятностью, то вероятность может быть вычислена через вероятности микросостояний.
Термодинамической вероятностью W называют число микросостояний, которыми может быть осуществлено данное микроскопическое состояние. Свойства термодинамической вероятности похожи на свойства энтропии – обе максимальны в состоянии равновесия, а переход к равновесию связан с их ростом.

\begin{enumerate}
\item{Поднимание и опускание туловища из положения лежа, ноги закреплены, руки за головой.}
\item{Тест на силовую подготовленность – сгибание-разгибание рук в упоре лежа.}
\item{Измерение гибкости.}
\item{Прыжок в длину с места.}
\end{enumerate}
Стоит отметить, что причисление к группе, в которой применяются сниженные нормативы, обусловлено не противопоказаниями к спортивной активности, а лишь возможной опасностью при повышенных нагрузках. В то же время определённые регулярные тренировки необходимы для полноценного развития детского организма. 
\newpage

\section{Статическая энтропия.}
Формула Больцмана позволяет дать энтропии следующее статистическое толкование: энтропия является мерой неупорядоченности системы.
Действительно, чем больше число микросостояний, реализующих данное макросостояние, тем больше энтропия. В состоянии равновесия — самого вероятного состояния системы — число микросостояний максимально, при этом максимальна и энтропия.
Таким образом, второе начало термодинамики можно сформулировать как закон возрастания энтропии замкнутой системы при необратимых процессах (две формулировки):
\begin{itemize}
\itemлюбой необратимый процесс в замкнутой системе происходит так, что энтропия системы при этом возрастает;
\itemв процессах, происходящих в замкнутой системе, энтропия не убывает.
\end{itemize}
При статистическом толковании энтропии это означает, что процессы в замкнутой системе идут в направлении увеличения числа микросостояний — иными словами, от менее вероятных состояний к более вероятным, до тех пор пока вероятность состояния не станет максимальной. Следовательно, возрастание энтропии означает переход системы из менее вероятных в более вероятные состояния. Согласно выражениям описанным выше термодинамическая вероятность состояний, как и энтропия, замкнутой системы не может уменьшаться.
Для «малых» систем, состоящих из малого числа частиц, могут наблюдаться относительно большие флуктуации, т.е. энтропия и термодинамическая вероятность состояний замкнутой системы на определенном отрезке времени могут не возрастать, а убывать или оставаться постоянными. В системах с очень большим числом частиц все флуктуации малы.
Таким образом, второе начало термодинамики является статистическим законом и выражает необходимые закономерности хаотического движения большого числа частиц, составляющих замкнутую систему.

\begin{itemize}
\begin{itemize}
\itemЗаниматься только с учителем или его помощником, обязательно выполнять все их требования (запрещается без педагога выполнять сложные и неизвестные упражнения).

\itemОбязательное выполнение разминки, способствующей разогреванию основных групп мышц.

\itemНе покидать без разрешения учителя место занятий.

\itemВыполнение упражнений только на исправном оборудовании; бережно относиться к инвентарю и оборудованию; закончив выполнение упражнений с инвентарём (мячи, палки, скакалки…) класть его в место его хранения (специально отведённое место).

\itemСоответствие спортивной одежды и обуви занятиям физической культурой, погодным и другим условиям. Обувь должна быть чистой и с нескользкой подошвой.

\itemОдежду и обувь для физической культуры необходимо приносить с собой в сумке (пакете). Перед тем, как приступить к занятиям необходимо, надеть спортивный костюм и обувь. После окончания занятий необходимо снять спортивный костюм и обувь, надеть школьную форму (или другую одежду и обувь), вымыть лицо и руки с мылом.

\itemНа спортивной площадке и в зале не сорить, следить за чистотой.

\itemУчастие в занятиях только при хорошем самочувствии.

\itemВо время бега на короткие дистанции нельзя перебегать на соседнюю дорожку, это может привести к столкновение учащихся. Все беговые соревнования проводят при движения в одном направлении.
\end{itemize}
\end{itemize}

\newpage

\section{Информационная энтропия.}
Понятие информационной энтропии определено Шенноном для случая дискретных данных, и похоже на понятие термодинамической энтропии. Это - величина, обозначающая количество информации, содержащееся в данном сообщении (или последовательности сигналов). По Шеннону информация снятая неопределенность. Точнее получение информации - необходимое условие для снятия неопределенности. Неопределенность возникает в ситуации выбора. Задача, которая решается в ходе снятия неопределённости – уменьшение количества рассматриваемых вариантов (уменьшение разнообразия), и в итоге выбор одного соответствующего ситуации варианта из числа возможных. Снятие неопределенности даёт возможность принимать обоснованные решения и действовать. В этом управляющая роль информации. 
Информационная энтропия - мера хаотичности информации или мера внутренней неупорядоченности информационной системы. Энтропия увеличивается при хаотическом распределении информационных ресурсов и уменьшается при их упорядочении. 
Информационная энтропи́я - мера хаотичности информации, неопределённость появления какого-либо символа первичного алфавита. При отсутствии информационных потерь численно равна количеству информации на символ передаваемого сообщения. 
Информационная энтропия - неопределённость появления какого-либо символа первичного алфавита. При отсутствии информационных потерь численно равна количеству информации на символ передаваемого сообщения. Например, в последовательности букв, составляющих какое-либо предложение на русском языке, разные буквы появляются с разной частотой, поэтому неопределённость появления для некоторых букв меньше, чем для других. Если же учесть, что некоторые сочетания букв (в этом случае говорят об энтропии n-ого порядка) встречаются очень редко, то неопределённость ещё более уменьшается. Понятие информационной энтропии определено Шенноном для случая дискретных данных и весьма похоже на понятие термодинамической энтропии. Это величина, обозначающая количество информации, содержащееся в данном сообщении (или последовательности сигналов). Сведения об информационной энтропии необходимы для повышения надёжности передачи сигналов. Именно на неё ориентируются при задании избыточной информации, передаваемой по линии связи.

\newpage

\section*{Заключение.}
Энтропия является фундаментальной физической величиной. С введением энтропии завершился этап формирования основных понятий термодинамики. Следующий этап начался с выяснения физического смысла энтропии. Трактовка энтропии с помощью принципа Больцмана, то есть установление связи между энтропией и вероятностью состояния системы или ее статистическим весом, позволила энтропии выйти за пределы термодинамики и равновесной статистической физики и проникнуть в другие области науки, например в теорию информации.
Научный потенциал энтропии далеко не исчерпан уже существующими приложениями. В перспективе проникновение энтропии в новую область науки – синергетику, которая занимается изучением закономерностей образования и распада пространственновременных структур в системах различной природы: физических, химических, биологических, экономических, социальных и т.д. Триумфальное шествие энтропии продолжается.
 

\newpage

\section*{Литература.}
\begin{enumerate}
\item{Термодинамика вчера, сегодня и завтра // А.И. Осипов. Соросовский Образовательный Журнал. 1999. № 4. С. 79; № 5. С. 91.}
\item{Математическая энциклопедия / Гл. ред. И.М. Виноградов. М.: Сов. эциклопедия. 1985. Т. 5. }
\item{Энтропия и её роль в науке / А.И. Осипов, А.В.Увалов.}
\end{enumerate}
\end{document}